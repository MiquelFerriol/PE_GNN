{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xDOTzsfMv63"
   },
   "source": [
    "# Demo GNN with IGNNITION\n",
    "\n",
    "## QM9\n",
    "### **Problem**: The QM9 dataset contains information about 134k organic molecules containing Hydrogen (H), Carbon (C), Nitrogen (N) and Fluorine (F). For each molecule, computational quantum mechanical modeling was used to find each atom's “positions” as well as a wide range of interesting and fundamental chemical properties, such as dipole moment, isotropic polarizability, enthalpy at 25ºC, etc.\n",
    "\n",
    "https://arxiv.org/abs/1704.01212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVb2tPgCkBiS"
   },
   "source": [
    "---\n",
    "# Prepare the environment\n",
    "\n",
    "#### **Note**: Follow the instructions below to finish the installation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installing libraries and load resources"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install pysmiles\n",
    "!pip install rdkit\n",
    "\n",
    "!pip uninstall urllib3 -y\n",
    "!pip uninstall requests -y\n",
    "!pip install urllib3==1.26.18\n",
    "!pip install --upgrade requests\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAoY-pkR1GTH",
    "outputId": "08090d8c-107e-4285-d6ce-af211ce97a9c"
   },
   "source": [
    "import random\n",
    "import os\n",
    "import ignnition\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "import pysmiles"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Download and create the dataset"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEnrunxq13BJ",
    "outputId": "80b0f199-4a2e-4a8f-e957-9d99f397fa97"
   },
   "source": [
    "# QM9 dataset obtention and processing.\n",
    "#\n",
    "# This script downloads and transforms the molecules in the QM9 dataset into Networkx graphs, to use\n",
    "# in iGNNition example.\n",
    "# For the data transformation to work, additional cheminformatics packages are needed, such as:\n",
    "# - pysmiles -> https://pypi.org/project/pysmiles/\n",
    "# - rdkit -> https://www.rdkit.org/docs/GettingStartedInPython.html\n",
    "#\n",
    "# References:\n",
    "# - L. Ruddigkeit, R. van Deursen, L. C. Blum, J.-L. Reymond,\n",
    "#   Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17,\n",
    "#   J. Chem. Inf. Model. 52, 2864–2875, 2012.\n",
    "# - R. Ramakrishnan, P. O. Dral, M. Rupp, O. A. von Lilienfeld,\n",
    "#   Quantum chemistry structures and properties of 134 kilo molecules,\n",
    "#   Scientific Data 1, 140022, 2014.\n",
    "\n",
    "\n",
    "# Parameters to determine dataset generation\n",
    "empty_dirs = True\n",
    "limit = 7000  # Limit number of files to take from dataset. None to take all\n",
    "qm9_url = \"https://s3-eu-west-1.amazonaws.com/pstorage-npg-968563215/3195389/dsgdb9nsd.xyz.tar.bz2\"\n",
    "random_seed = 42\n",
    "raw_dir = Path(\"data/raw\")\n",
    "train_dir = Path(\"data/train\")\n",
    "train_samples = 5000\n",
    "validation_dir = Path(\"data/validation\")\n",
    "validation_samples = 1000\n",
    "\n",
    "\n",
    "def _empty_dirs(dirs=None):\n",
    "    if dirs is None:\n",
    "        return\n",
    "    elif isinstance(dirs, (Path, str)):\n",
    "        dirs = [Path(dirs)]\n",
    "    for _dir in dirs:\n",
    "        assert isinstance(_dir, Path)\n",
    "        for file in [f for f in _dir.glob(\"*\") if f.is_file()]:\n",
    "            file.unlink()\n",
    "\n",
    "\n",
    "def get_graph_from_molecule(molecule):\n",
    "    # Parse molecule file\n",
    "    na = int(molecule[0][0])\n",
    "    coordinates = [\n",
    "        [c[0], float(c[1].replace(\"*^\", \"e\")), float(c[2].replace(\"*^\", \"e\")),\n",
    "            float(c[3].replace(\"*^\", \"e\")), float(c[4].replace(\"*^\", \"e\"))]\n",
    "        for c in molecule[2:(na+2)]\n",
    "    ]\n",
    "    properties = dict(zip(\n",
    "        [\n",
    "            \"id\", \"rotational_a\", \"rotational_b\", \"rotational_c\", \"dipole_moment\", \"polarizability\",\n",
    "            \"homo_energy\", \"lumo_energy\", \"spatial_extent\", \"internal_energy_0k\",\n",
    "            \"internal_energy_298k\", \"free_energy\", \"heat_capacity\"],\n",
    "        [float(e.replace(\"gdb\", \"\").strip()) for e in molecule[1][:-1]]\n",
    "    ))\n",
    "    smiles = molecule[na+3][0]\n",
    "    graph = pysmiles.read_smiles(smiles, explicit_hydrogen=True)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # One-hot encode element\n",
    "    nx.set_node_attributes(graph, {\n",
    "        k: {\n",
    "            \"entity\": \"atom\",\n",
    "            \"element_c\": int(d[\"element\"] == \"C\"),\n",
    "            \"element_f\": int(d[\"element\"] == \"F\"),\n",
    "            \"element_h\": int(d[\"element\"] == \"H\"),\n",
    "            \"element_n\": int(d[\"element\"] == \"N\"),\n",
    "            \"element_o\": int(d[\"element\"] == \"O\"),\n",
    "            \"acceptor\": int(d[\"charge\"] > 0),\n",
    "            \"donor\": int(d[\"charge\"] < 0),\n",
    "        }\n",
    "        for k, d in dict(graph.nodes(data=True)).items()\n",
    "    })\n",
    "    # Add Chem molecule attributes\n",
    "    hybridizations = [\"SP\", \"SP2\", \"SP3\"]\n",
    "    nx.set_node_attributes(graph, {\n",
    "        **{\n",
    "            atom.GetIdx(): {\n",
    "                \"aromatic\": int(atom.GetIsAromatic()),\n",
    "                \"atomic_number\": atom.GetAtomicNum(),\n",
    "                \"hybridization_null\": int(str(atom.GetHybridization()) not in hybridizations),\n",
    "                \"hybridization_sp\": int(str(atom.GetHybridization()) == hybridizations[0]),\n",
    "                \"hybridization_sp2\": int(str(atom.GetHybridization()) == hybridizations[1]),\n",
    "                \"hybridization_sp3\": int(str(atom.GetHybridization()) == hybridizations[2]),\n",
    "                \"hydrogen_count\": atom.GetNumImplicitHs(),\n",
    "            }\n",
    "            for atom in mol.GetAtoms()\n",
    "        }, **{\n",
    "            k: {\n",
    "                \"aromatic\": 0,\n",
    "                \"atomic_number\": 1,\n",
    "                \"hybridization_null\": 1,\n",
    "                \"hybridization_sp\": 0,\n",
    "                \"hybridization_sp2\": 0,\n",
    "                \"hybridization_sp3\": 0,\n",
    "                \"hydrogen_count\": 0\n",
    "            }\n",
    "            for k in range(mol.GetNumAtoms(), graph.number_of_nodes())\n",
    "        }\n",
    "    })\n",
    "    # Set edge attributes\n",
    "    nx.set_edge_attributes(graph, {\n",
    "        (src, tgt): {\n",
    "            \"distance\": np.sqrt(np.sum(np.square(\n",
    "                np.array(coordinates[tgt][1:]) - np.array(coordinates[src][1:])\n",
    "            ))),\n",
    "            \"order_1\": int(d[\"order\"] == 1),\n",
    "            \"order_1_5\": int(d[\"order\"] == 1.5),\n",
    "            \"order_2\": int(d[\"order\"] == 2),\n",
    "            \"order_3\": int(d[\"order\"] == 3),\n",
    "        }\n",
    "        for src, tgt, d in list(graph.edges(data=True))\n",
    "    })\n",
    "    # Add graph level targets\n",
    "    for key in [k for k in properties if k != \"id\"]:\n",
    "        graph.graph[key] = properties[key]\n",
    "    # Turn into directed graph\n",
    "    digraph = nx.DiGraph(graph)\n",
    "    return digraph\n",
    "\n",
    "\n",
    "def join_graphs_into_dataset(files, output_dir, output_file_name=\"data.json\", empty_dirs=False):\n",
    "    if empty_dirs:\n",
    "        _empty_dirs(output_dir)\n",
    "    graphs = [json.load(open(file, \"r\")) for file in files]\n",
    "    with open(output_dir / output_file_name, \"w\") as fp:\n",
    "        json.dump(graphs, fp)\n",
    "\n",
    "\n",
    "def qm9_download_and_extract(\n",
    "    url, empty_dirs=False, limit=None, output_dir=\"data/raw\", output_prefix=\"mol\", process_func=None\n",
    "):\n",
    "    \"\"\"Download QM9 to temporary file and extract it to data/raw folder\"\"\"\n",
    "    if process_func is None:\n",
    "        process_func = get_graph_from_molecule\n",
    "    if empty_dirs:\n",
    "        _empty_dirs(output_dir)\n",
    "    with tempfile.TemporaryFile() as fp:\n",
    "        print(\"Downloading tar file containing molecules...\")\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        fp.write(r.content)\n",
    "        fp.seek(0)\n",
    "        tar = tarfile.open(fileobj=fp)\n",
    "        elem = tar.next()\n",
    "        i = 0\n",
    "        print(f\"Extracting & transforming molecule files to {output_dir}...\")\n",
    "        while(elem is not None and limit is not None and i < limit):\n",
    "            file = tar.extractfile(elem)\n",
    "            molecule = [l.split(\"\\t\") for l in file.read().decode(\"utf-8\").split(\"\\n\")]\n",
    "            graph = process_func(molecule)\n",
    "            filepath = Path(output_dir) / f\"{output_prefix}_{i}.json\"\n",
    "            with filepath.open(\"w\") as _f:\n",
    "                json.dump(nx.readwrite.json_graph.node_link_data(graph), _f)\n",
    "            elem = tar.next()\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def split_traing_validation(\n",
    "    raw_dir, train_dir, validation_dir, train_samples, validation_samples, empty_dirs=False\n",
    "):\n",
    "    if empty_dirs:\n",
    "        _empty_dirs([train_dir, validation_dir])\n",
    "    files = np.array(list(Path(raw_dir).glob(\"*.json\")))\n",
    "    assert files.shape[0] > train_samples+validation_samples, \\\n",
    "        \"Train + Validation samples exceed number of files available.\"\n",
    "    np.random.shuffle(files)\n",
    "    training_files = files[validation_samples:(train_samples + validation_samples)]\n",
    "    validation_files = files[:validation_samples]\n",
    "    print(f\"Copying training graphs into {raw_dir / 'traing'}\")\n",
    "    for file in training_files:\n",
    "        shutil.copy(file, raw_dir / \"train\")\n",
    "    print(f\"Joining training graphs into {train_dir}\")\n",
    "    join_graphs_into_dataset(training_files, output_dir=train_dir)\n",
    "    print(f\"Copying validation graphs into {raw_dir / 'validation'}\")\n",
    "    for file in validation_files:\n",
    "        shutil.copy(file, raw_dir / \"validation\")\n",
    "    print(f\"Joining validation graphs into {validation_dir}\")\n",
    "    join_graphs_into_dataset(validation_files, output_dir=validation_dir)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "for _dir in [raw_dir, train_dir, validation_dir, raw_dir / \"train\", raw_dir / \"validation\"]:\n",
    "    os.makedirs(_dir, exist_ok=True)\n",
    "qm9_download_and_extract(url=qm9_url, limit=limit, output_dir=raw_dir, empty_dirs=empty_dirs)\n",
    "split_traing_validation(\n",
    "    raw_dir=raw_dir, train_dir=train_dir, validation_dir=validation_dir,\n",
    "    train_samples=train_samples, validation_samples=validation_samples, empty_dirs=empty_dirs\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDYQM2HX49dx"
   },
   "source": [
    "# GNN model training\n",
    "# Run the training of your GNN model\n",
    "# </u>**Note**</u>: You can stop the training whenever you want to continue making predictions below\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "IiePG6oWKJ6n",
    "outputId": "76cc8552-04d9-4c38-aeca-68f17108df30"
   },
   "source": [
    "import ignnition\n",
    "\n",
    "model = ignnition.create_model(model_dir= './')\n",
    "model.computational_graph()\n",
    "model.train_and_validate()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "0xDOTzsfMv63"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
