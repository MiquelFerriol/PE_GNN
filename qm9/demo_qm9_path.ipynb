{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xDOTzsfMv63"
   },
   "source": [
    "# Demo GNN with IGNNITION\n",
    "\n",
    "## QM9\n",
    "### **Problem**: The QM9 dataset contains information about 134k organic molecules containing Hydrogen (H), Carbon (C), Nitrogen (N) and Fluorine (F). For each molecule, computational quantum mechanical modeling was used to find each atom's “positions” as well as a wide range of interesting and fundamental chemical properties, such as dipole moment, isotropic polarizability, enthalpy at 25ºC, etc.\n",
    "\n",
    "https://arxiv.org/abs/1704.01212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVb2tPgCkBiS"
   },
   "source": [
    "---\n",
    "# Prepare the environment\n",
    "\n",
    "#### **Note**: Follow the instructions below to finish the installation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installing libraries and load resources"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T22:26:51.473248Z",
     "start_time": "2024-04-08T22:26:42.673790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install pysmiles\n",
    "!pip install rdkit\n",
    "\n",
    "!pip uninstall urllib3 -y\n",
    "!pip uninstall requests -y\n",
    "!pip install urllib3==1.26.18\n",
    "!pip install --upgrade requests\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysmiles in d:\\vens\\pe_gnn\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: pbr in d:\\vens\\pe_gnn\\lib\\site-packages (from pysmiles) (6.0.0)\n",
      "Requirement already satisfied: networkx in d:\\vens\\pe_gnn\\lib\\site-packages (from pysmiles) (2.5.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in d:\\vens\\pe_gnn\\lib\\site-packages (from networkx->pysmiles) (4.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in d:\\vens\\pe_gnn\\lib\\site-packages (2023.3.2)\n",
      "Requirement already satisfied: numpy in d:\\vens\\pe_gnn\\lib\\site-packages (from rdkit) (1.19.5)\n",
      "Requirement already satisfied: Pillow in d:\\vens\\pe_gnn\\lib\\site-packages (from rdkit) (9.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: urllib3 1.26.18\n",
      "Uninstalling urllib3-1.26.18:\n",
      "  Successfully uninstalled urllib3-1.26.18\n",
      "Found existing installation: requests 2.31.0\n",
      "Uninstalling requests-2.31.0:\n",
      "  Successfully uninstalled requests-2.31.0\n",
      "Collecting urllib3==1.26.18\n",
      "  Obtaining dependency information for urllib3==1.26.18 from https://files.pythonhosted.org/packages/b0/53/aa91e163dcfd1e5b82d8a890ecf13314e3e149c05270cc644581f77f17fd/urllib3-1.26.18-py2.py3-none-any.whl.metadata\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3\n",
      "Successfully installed urllib3-1.26.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\vens\\pe_gnn\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\vens\\pe_gnn\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\vens\\pe_gnn\\lib\\site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\vens\\pe_gnn\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Installing collected packages: requests\n",
      "Successfully installed requests-2.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAoY-pkR1GTH",
    "outputId": "08090d8c-107e-4285-d6ce-af211ce97a9c",
    "ExecuteTime": {
     "end_time": "2024-04-08T22:28:33.383049Z",
     "start_time": "2024-04-08T22:28:33.366037Z"
    }
   },
   "source": [
    "import random\n",
    "import os\n",
    "import ignnition\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "import pysmiles"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Download and create the dataset"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEnrunxq13BJ",
    "outputId": "80b0f199-4a2e-4a8f-e957-9d99f397fa97",
    "ExecuteTime": {
     "end_time": "2024-04-08T22:29:29.397083Z",
     "start_time": "2024-04-08T22:28:38.035122Z"
    }
   },
   "source": [
    "# QM9 dataset obtention and processing.\n",
    "#\n",
    "# This script downloads and transforms the molecules in the QM9 dataset into Networkx graphs, to use\n",
    "# in iGNNition example.\n",
    "# For the data transformation to work, additional cheminformatics packages are needed, such as:\n",
    "# - pysmiles -> https://pypi.org/project/pysmiles/\n",
    "# - rdkit -> https://www.rdkit.org/docs/GettingStartedInPython.html\n",
    "#\n",
    "# References:\n",
    "# - L. Ruddigkeit, R. van Deursen, L. C. Blum, J.-L. Reymond,\n",
    "#   Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17,\n",
    "#   J. Chem. Inf. Model. 52, 2864–2875, 2012.\n",
    "# - R. Ramakrishnan, P. O. Dral, M. Rupp, O. A. von Lilienfeld,\n",
    "#   Quantum chemistry structures and properties of 134 kilo molecules,\n",
    "#   Scientific Data 1, 140022, 2014.\n",
    "\n",
    "# Parameters to determine dataset generation\n",
    "empty_dirs = True\n",
    "limit = 7000  # Limit number of files to take from dataset. None to take all\n",
    "qm9_url = \"https://s3-eu-west-1.amazonaws.com/pstorage-npg-968563215/3195389/dsgdb9nsd.xyz.tar.bz2\"\n",
    "random_seed = 42\n",
    "raw_dir = Path(\"data/raw\")\n",
    "train_dir = Path(\"data/train\")\n",
    "train_samples = 5000\n",
    "validation_dir = Path(\"data/validation\")\n",
    "validation_samples = 1000\n",
    "\n",
    "\n",
    "def _empty_dirs(dirs=None):\n",
    "    if dirs is None:\n",
    "        return\n",
    "    elif isinstance(dirs, (Path, str)):\n",
    "        dirs = [Path(dirs)]\n",
    "    for _dir in dirs:\n",
    "        assert isinstance(_dir, Path)\n",
    "        for file in [f for f in _dir.glob(\"*\") if f.is_file()]:\n",
    "            file.unlink()\n",
    "\n",
    "\n",
    "def get_graph_from_molecule(molecule):\n",
    "    # Parse molecule file\n",
    "    na = int(molecule[0][0])\n",
    "    coordinates = [\n",
    "        [c[0], float(c[1].replace(\"*^\", \"e\")), float(c[2].replace(\"*^\", \"e\")),\n",
    "            float(c[3].replace(\"*^\", \"e\")), float(c[4].replace(\"*^\", \"e\"))]\n",
    "        for c in molecule[2:(na+2)]\n",
    "    ]\n",
    "    properties = dict(zip(\n",
    "        [\n",
    "            \"id\", \"rotational_a\", \"rotational_b\", \"rotational_c\", \"dipole_moment\", \"polarizability\",\n",
    "            \"homo_energy\", \"lumo_energy\", \"spatial_extent\", \"internal_energy_0k\",\n",
    "            \"internal_energy_298k\", \"free_energy\", \"heat_capacity\"],\n",
    "        [float(e.replace(\"gdb\", \"\").strip()) for e in molecule[1][:-1]]\n",
    "    ))\n",
    "    smiles = molecule[na+3][0]\n",
    "    graph = pysmiles.read_smiles(smiles, explicit_hydrogen=True)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # One-hot encode element\n",
    "    nx.set_node_attributes(graph, {\n",
    "        k: {\n",
    "            \"entity\": \"atom\",\n",
    "            \"element_c\": int(d[\"element\"] == \"C\"),\n",
    "            \"element_f\": int(d[\"element\"] == \"F\"),\n",
    "            \"element_h\": int(d[\"element\"] == \"H\"),\n",
    "            \"element_n\": int(d[\"element\"] == \"N\"),\n",
    "            \"element_o\": int(d[\"element\"] == \"O\"),\n",
    "            \"acceptor\": int(d[\"charge\"] > 0),\n",
    "            \"donor\": int(d[\"charge\"] < 0),\n",
    "        }\n",
    "        for k, d in dict(graph.nodes(data=True)).items()\n",
    "    })\n",
    "    # Add Chem molecule attributes\n",
    "    hybridizations = [\"SP\", \"SP2\", \"SP3\"]\n",
    "    nx.set_node_attributes(graph, {\n",
    "        **{\n",
    "            atom.GetIdx(): {\n",
    "                \"aromatic\": int(atom.GetIsAromatic()),\n",
    "                \"atomic_number\": atom.GetAtomicNum(),\n",
    "                \"hybridization_null\": int(str(atom.GetHybridization()) not in hybridizations),\n",
    "                \"hybridization_sp\": int(str(atom.GetHybridization()) == hybridizations[0]),\n",
    "                \"hybridization_sp2\": int(str(atom.GetHybridization()) == hybridizations[1]),\n",
    "                \"hybridization_sp3\": int(str(atom.GetHybridization()) == hybridizations[2]),\n",
    "                \"hydrogen_count\": atom.GetNumImplicitHs(),\n",
    "            }\n",
    "            for atom in mol.GetAtoms()\n",
    "        }, **{\n",
    "            k: {\n",
    "                \"aromatic\": 0,\n",
    "                \"atomic_number\": 1,\n",
    "                \"hybridization_null\": 1,\n",
    "                \"hybridization_sp\": 0,\n",
    "                \"hybridization_sp2\": 0,\n",
    "                \"hybridization_sp3\": 0,\n",
    "                \"hydrogen_count\": 0\n",
    "            }\n",
    "            for k in range(mol.GetNumAtoms(), graph.number_of_nodes())\n",
    "        }\n",
    "    })\n",
    "    # Set edge attributes\n",
    "    nx.set_edge_attributes(graph, {\n",
    "        (src, tgt): {\n",
    "            \"distance\": np.sqrt(np.sum(np.square(\n",
    "                np.array(coordinates[tgt][1:]) - np.array(coordinates[src][1:])\n",
    "            ))),\n",
    "            \"order_1\": int(d[\"order\"] == 1),\n",
    "            \"order_1_5\": int(d[\"order\"] == 1.5),\n",
    "            \"order_2\": int(d[\"order\"] == 2),\n",
    "            \"order_3\": int(d[\"order\"] == 3),\n",
    "        }\n",
    "        for src, tgt, d in list(graph.edges(data=True))\n",
    "    })\n",
    "    # Add graph level targets\n",
    "    for key in [k for k in properties if k != \"id\"]:\n",
    "        graph.graph[key] = properties[key]\n",
    "    # Turn into directed graph\n",
    "    digraph = nx.DiGraph(graph)\n",
    "    return digraph\n",
    "\n",
    "\n",
    "def join_graphs_into_dataset(files, output_dir, output_file_name=\"data.json\", empty_dirs=False):\n",
    "    if empty_dirs:\n",
    "        _empty_dirs(output_dir)\n",
    "    graphs = [json.load(open(file, \"r\")) for file in files]\n",
    "    with open(output_dir / output_file_name, \"w\") as fp:\n",
    "        json.dump(graphs, fp)\n",
    "\n",
    "\n",
    "def qm9_download_and_extract(\n",
    "    url, empty_dirs=False, limit=None, output_dir=\"data/raw\", output_prefix=\"mol\", process_func=None\n",
    "):\n",
    "    \"\"\"Download QM9 to temporary file and extract it to data/raw folder\"\"\"\n",
    "    if process_func is None:\n",
    "        process_func = get_graph_from_molecule\n",
    "    if empty_dirs:\n",
    "        _empty_dirs(output_dir)\n",
    "    with tempfile.TemporaryFile() as fp:\n",
    "        print(\"Downloading tar file containing molecules...\")\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        fp.write(r.content)\n",
    "        fp.seek(0)\n",
    "        tar = tarfile.open(fileobj=fp)\n",
    "        elem = tar.next()\n",
    "        i = 0\n",
    "        print(f\"Extracting & transforming molecule files to {output_dir}...\")\n",
    "        while(elem is not None and limit is not None and i < limit):\n",
    "            file = tar.extractfile(elem)\n",
    "            molecule = [l.split(\"\\t\") for l in file.read().decode(\"utf-8\").split(\"\\n\")]\n",
    "            graph = process_func(molecule)\n",
    "            filepath = Path(output_dir) / f\"{output_prefix}_{i}.json\"\n",
    "            with filepath.open(\"w\") as _f:\n",
    "                json.dump(nx.readwrite.json_graph.node_link_data(graph), _f)\n",
    "            elem = tar.next()\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def split_traing_validation(\n",
    "    raw_dir, train_dir, validation_dir, train_samples, validation_samples, empty_dirs=False\n",
    "):\n",
    "    if empty_dirs:\n",
    "        _empty_dirs([train_dir, validation_dir])\n",
    "    files = np.array(list(Path(raw_dir).glob(\"*.json\")))\n",
    "    assert files.shape[0] > train_samples+validation_samples, \\\n",
    "        \"Train + Validation samples exceed number of files available.\"\n",
    "    np.random.shuffle(files)\n",
    "    training_files = files[validation_samples:(train_samples + validation_samples)]\n",
    "    validation_files = files[:validation_samples]\n",
    "    print(f\"Copying training graphs into {raw_dir / 'traing'}\")\n",
    "    for file in training_files:\n",
    "        shutil.copy(file, raw_dir / \"train\")\n",
    "    print(f\"Joining training graphs into {train_dir}\")\n",
    "    join_graphs_into_dataset(training_files, output_dir=train_dir)\n",
    "    print(f\"Copying validation graphs into {raw_dir / 'validation'}\")\n",
    "    for file in validation_files:\n",
    "        shutil.copy(file, raw_dir / \"validation\")\n",
    "    print(f\"Joining validation graphs into {validation_dir}\")\n",
    "    join_graphs_into_dataset(validation_files, output_dir=validation_dir)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "for _dir in [raw_dir, train_dir, validation_dir, raw_dir / \"train\", raw_dir / \"validation\"]:\n",
    "    os.makedirs(_dir, exist_ok=True)\n",
    "qm9_download_and_extract(url=qm9_url, limit=limit, output_dir=raw_dir, empty_dirs=empty_dirs)\n",
    "split_traing_validation(\n",
    "    raw_dir=raw_dir, train_dir=train_dir, validation_dir=validation_dir,\n",
    "    train_samples=train_samples, validation_samples=validation_samples, empty_dirs=empty_dirs\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tar file containing molecules...\n",
      "Extracting & transforming molecule files to data\\raw...\n",
      "Copying training graphs into data\\raw\\traing\n",
      "Joining training graphs into data\\train\n",
      "Copying validation graphs into data\\raw\\validation\n",
      "Joining validation graphs into data\\validation\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDYQM2HX49dx"
   },
   "source": [
    "# GNN model training\n",
    "# Run the training of your GNN model\n",
    "# </u>**Note**</u>: You can stop the training whenever you want to continue making predictions below\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "IiePG6oWKJ6n",
    "outputId": "76cc8552-04d9-4c38-aeca-68f17108df30",
    "ExecuteTime": {
     "end_time": "2024-04-08T22:30:25.645194Z",
     "start_time": "2024-04-08T22:30:25.591180Z"
    }
   },
   "source": [
    "import ignnition\n",
    "\n",
    "model = ignnition.create_model(model_dir= './')\n",
    "model.computational_graph()\n",
    "model.train_and_validate()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\n",
      "Processing the described model...\n",
      "---------------------------------------------------------------------------\n",
      "\u001B[0m\r\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "None is not of type 'number', 'string'\n\nFailed validating 'type' in schema['properties']['message_passing']['properties']['num_iterations']:\n    {'description': 'Number of iterations the algorithm',\n     'type': ['number', 'string']}\n\nOn instance['message_passing']['num_iterations']:\n    None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10436\\356341938.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mignnition\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mignnition\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_dir\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'./'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcomputational_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_and_validate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\vens\\pe_gnn\\lib\\site-packages\\ignnition\\error_handling.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    482\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    483\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 484\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    485\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mIgnnitionException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    486\u001B[0m             \u001B[0mFAIL\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'\\033[91m'\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\vens\\pe_gnn\\lib\\site-packages\\ignnition\\__init__.py\u001B[0m in \u001B[0;36mcreate_model\u001B[1;34m(model_dir)\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[0mPath\u001B[0m \u001B[0mto\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mdirectory\u001B[0m \u001B[0mwhere\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmodel_description\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglobal_variables\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mtrain_options\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0myaml\u001B[0m \u001B[0mare\u001B[0m \u001B[0mfound\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \"\"\"\n\u001B[1;32m---> 16\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mIgnnitionModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\vens\\pe_gnn\\lib\\site-packages\\ignnition\\ignnition_model.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, model_dir)\u001B[0m\n\u001B[0;32m    161\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 163\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_info\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__create_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGenerator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\vens\\pe_gnn\\lib\\site-packages\\ignnition\\ignnition_model.py\u001B[0m in \u001B[0;36m__create_model\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    521\u001B[0m             \u001B[1;34m\"\\nProcessing the described model...\\n----------------------------------------------\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    522\u001B[0m             \"-----------------------------\\n\")\n\u001B[1;32m--> 523\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mYamlPreprocessing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_dir\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# read json\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    524\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    525\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__create_gnn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrequire_warm_start\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\vens\\pe_gnn\\lib\\site-packages\\ignnition\\yaml_preprocessing.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, model_dir)\u001B[0m\n\u001B[0;32m    119\u001B[0m         \u001B[1;31m# validate with the schema\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresources\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ignnition'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"schema.json\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mschema_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 121\u001B[1;33m             \u001B[0mvalidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__read_json\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mschema_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# validate that the json is well defined\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    122\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[1;31m# add the global variables (if any)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\vens\\pe_gnn\\lib\\site-packages\\jsonschema\\validators.py\u001B[0m in \u001B[0;36mvalidate\u001B[1;34m(instance, schema, cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    932\u001B[0m     \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_match\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalidator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miter_errors\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    933\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0merror\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 934\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0merror\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    935\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    936\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValidationError\u001B[0m: None is not of type 'number', 'string'\n\nFailed validating 'type' in schema['properties']['message_passing']['properties']['num_iterations']:\n    {'description': 'Number of iterations the algorithm',\n     'type': ['number', 'string']}\n\nOn instance['message_passing']['num_iterations']:\n    None"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "0xDOTzsfMv63"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
